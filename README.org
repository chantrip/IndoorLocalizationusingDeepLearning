#+TITLE: Indoor Localization
#+DATE: Time-stamp: <2017-08-19 10:46:17 Kyeong Soo (Joseph) Kim>
#+OPTIONS: toc:nil
#+STARTUP: showall

This is a repository for research on indoor localization based on wireless
fingerprinting techniques. For more details, please visit [[http://kyeongsoo.github.io/research/projects/indoor_localization/index.html][XJTLU SURF project
home page]].

* 2017-08-18
- Implement [[./python/bf_multi-label_classification.py][a multi-label classifier]] to address the issues described on
  2017-08-17: 3 building and 5 floor identifiers are [[https://en.wikipedia.org/wiki/One-hot][one-hot]] encoded into an
  8-dimensional vector (e.g., '001|01000') and classified with different class
  weights (e.g., 30 for buidlings and 1 for floors); the resulting
  one-hot-encoded vector is split into 3-dimensional building and 5-dimensional
  floor vectors and the index of a maximum value of each vector is returned as a
  classified class ([[./results/bf_multi-label_classification_out_20170819-010852.org][results]]).
  + Still, need to optimize parameters a lot.

* 2017-08-17
- Implement [[./python/bf_classification.py][a new program]], which calculates accuracies separately for building
  and floor classification, to investigate the hierarchical nature of the
  classification problem at hand; the deep-learning-based place recognition
  system described in the key paper[fn:1] does not take into account this and
  carries out classification based on flattened labels (i.e., (building, floor)
  -> 'building-floor'). We are now considering two options to guarantee 100%
  accuracy for the building classification:
  + Hierarchical classifier with a tree structure and multiple classifiers and
    data sets, which is a conventional approach and a reference for this
    investigation.
  + One classifier with a weighted loss function[fn:2]. In our case, however,
    the loss function does not give a closed-form gradient function, which
    forces us to use evolutionary algorithms (e.g., [[https://en.wikipedia.org/wiki/Genetic_algorithm][genetic algorithm]]) for
    training of neural network weights or [[https://github.com/fchollet/keras/issues/741][multi-label classification with
    different class weights]] (i.e., higher weights for buildings in our case).

* 2017-08-15
- Today, we further simplified the building/floor classification system by
  removing a hidden layer from the classifier (therefore no dropout), resulting
  in the configuration of '520-64-4-13' (including input and output layers) with
  loss=7.050603e-01 and accuracy=9.234923e-01 ([[./results/indoor_localization_deep_learning_out_20170815-203448.org][results]]). This might mean that
  the 4-dimensional data from the SAE encoder (64-4) can be linearly
  separable. Due to training of SAE encoder weights for the combined system,
  however, it needs further investigation.

* 2017-08-14
- We investigated whether a couple of strong RSSs in a fingerprint dominate the
  classification performance in building/floor classification. After many trials
  with different configurations, we could obtain more than 90% accuracies with
  the stacked-autoencoder (SAE) having 64-4-64 hidden layers (i.e., just 4
  dimension) and the classifier having just one 128-node hidden layer
  ([[./results/indoor_localization_deep_learning_out_20170814-184009.org][results]]). This implies that a small number of RSSs from access points (APs)
  deployed in a building/floor can give enough information for the
  building/floor classification; the localization on the same floor, by the way,
  would be quite different, where RSSs from possibly many APs have a significant
  impact on the localization performance.

* 2017-08-13
- We finally obtained [[./results/indoor_localization_deep_learning.org][more than 90% accuracies]] from [[./python/indoor_localization_deep_learning.py][this version]], which are
  comparable to the results of the key paper [fn:1] based on the [[https://archive.ics.uci.edu/ml/datasets/ujiindoorloc][UJIIndoorLoc
  Data Set]]; refer to the [[https://keras.io/getting-started/sequential-model-guide/#compilation][multi-class clarification example]] for classifier
  parameter settings.
- We [[./python/indoor_localization-2.ipynb][replace the activation functions of the hidden-layer from 'tanh' to 'relu']]
  per the second answer to [[https://stats.stackexchange.com/questions/218542/which-activation-function-for-output-layer][this question]] ([[./results/indoor_localization-2_20170813.csv][results]]). Compared to the case with
  'tanh', however, the results seem to not improve (a bit in line with the
  gut-feeling suggestions from [[https://datascience.stackexchange.com/questions/10048/what-is-the-best-keras-model-for-multi-class-classification][this]]).

* 2017-08-12
- We first tried [[./python/indoor_localization-1.ipynb][a feed-forward classifier with just one hidden layer]] per the
  comments from [[https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw][this]] ([[./results/indoor_localization-1_20170812.csv][results]]). (* /nh/: number of hidden layer nodes, /dr/:
  [[https://en.wikipedia.org/wiki/Dropout_(neural_networks)][dropout]] rate, /loss/: [[http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#theano.tensor.nnet.nnet.categorical_crossentropy][categorical cross-entropy]], /acc/: accuracy *).

* Footnotes

[fn:1] M. Nowicki and J. Wietrzykowski, "Low-effort place recognition with WiFi
fingerprints using deep learning," arXiv:1611.02049v2 [cs.RO] [[https://arxiv.org/abs/1611.02049v2][(arXiv)]]

[fn:2] T. Yamashita et al., "Cost-alleviative learning for deep convolutional
neural network-based facial part labeling," /IPSJ Transactions on Computer
Vision and Applications/, vol. 7, pp. 99-103, 2015. [[http://doi.org/10.2197/ipsjtcva.7.99][(DOI)]]

